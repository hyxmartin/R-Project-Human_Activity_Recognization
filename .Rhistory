setwd("C:/Users/Martin/Google Drive/Study Folder/CMU MSIT-BIDA/Courses/2 - 2018 Spring/95-791 Data Mining/Project/My Project")
nn <- 10
k <- 3
index <- seq(1, nn)
index
rand.index <- sample(index, nn)
rand.index
group <- seq_along(rand.index)%%k
group
chunk <- split(rand.index, group)
chunk
df <- my.data
library(gplots)
library(ggplot2)
library(FNN)
library(plyr)
library(zoo)
library(e1071)
# Utility function for importing data from a csv (comma-separated values, flat table) file
import.csv <- function(filename) {
return(read.csv(filename, dec = ",", sep = ";", header = TRUE))
}
# Utility function for exporting data to csv file
# Note that csv files are very portable, practically all tools understand them,
# including Microsoft Excel
write.csv <- function(ob, filename) {
write.table(ob, filename, quote = FALSE, sep = ";", dec = ",", row.names = FALSE)
}
my.data <- import.csv("dataset-har-PUC-Rio-ugulino.csv")
my.data <- transform(my.data,
z4 = as.integer(as.character(z4))
)
summary(my.data)
my.data <- my.data[!is.na(my.data$z4),]  # Drop Z4 na record
df <- my.data
nn <- nrow(df)  # number of data points
nf <- ncol(df)  # number of features
df <- df[,c(which(colnames(df) != output), which(colnames(df) == output))]  # Move output to the last column
output <- user
output <- 'user'
output <- 'class'
split.by <- 'user'
nn <- nrow(df)  # number of data points
nf <- ncol(df)  # number of features
nn
df <- df[,c(which(colnames(df) != output), which(colnames(df) == output))]  # Move output to the last column
head(df)
folds <- split(nn, df$split.by)
folds <- split(nn, df$user)
df$user
help(split)
folds <- split(nn, factor(df$user)
)
folds
folds <- split(nn, df$user)
folds
nn
folds <- split(1:nn, df$user)
folds
folds <- split(1:nn, df$split.by)
split.by
df$split.by
df[,c(which(colnames(df) == split.by))]
do_cv_class <- function(df, output, split.by, model) {
nn <- nrow(df)  # number of data points
nf <- ncol(df)  # number of features
df <- df[,c(which(colnames(df) != output), which(colnames(df) == output))]  # Move output to the last column
folds <- split(1:nn, df[,c(which(colnames(df) == split.by))])  # user split.by column to split folds.
score <- rep(NA, length(folds))  # create a list to hold the mse for each folds
for (ii in 1:length(folds)) {
test.index <- folds[[ii]]  # extract test index
train.data <- df[-test.index, ]  # assemble training data
test.data <- df[test.index, ]  # assemble test data
if (grepl("nn", model)) {
k.nn <- as.integer(sub("^\\D*(\\d+).*$", "\\1", model))  # parse the K nearest neighbor from model name
pred <- get_pred_knn(train.data, test.data, k.nn)  # run with addional parameter for knn model predictor
} else if (model == "nb") {
pred <- get_pred_nb(train.data, test.data)
} else if (model == "svm") {
pred <- get_pred_svm(train.data, test.data)
} else if (model == "logreg") {
pred <- get_pred_logit(train.data, test.data)
} else if (model == "default") {
pred <- get_pred_default(train.data, test.data)
}
true <- test.data[, c(which(colnames(df) == output))]  # extract true values from test set
accuracy <- true / length(pred)  # computer Accuracy
score[ii] <- accuracy  # save the score
}
return(df.output)
}
nn <- nrow(df)  # number of data points
nf <- ncol(df)  # number of features
df <- df[,c(which(colnames(df) != output), which(colnames(df) == output))]  # Move output to the last column
folds <- split(1:nn, df[,c(which(colnames(df) == split.by))])  # user split.by column to split folds.
score <- rep(NA, length(folds))  # create a list to hold the mse for each folds
score
nn <- nrow(df)  # number of data points
nf <- ncol(df)  # number of features
df <- df[,c(which(colnames(df) != output), which(colnames(df) == output))]  # Move output to the last column
folds <- split(1:nn, df[,c(which(colnames(df) == split.by))])  # user split.by column to split folds.
score <- rep(NA, length(folds))  # create a list to hold the mse for each folds
for (ii in 1:length(folds)) {
test.index <- folds[[ii]]  # extract test index
train.data <- df[-test.index, ]  # assemble training data
test.data <- df[test.index, ]  # assemble test data
# if (grepl("nn", model)) {
#   k.nn <- as.integer(sub("^\\D*(\\d+).*$", "\\1", model))  # parse the K nearest neighbor from model name
#   pred <- get_pred_knn(train.data, test.data, k.nn)  # run with addional parameter for knn model predictor
# } else if (model == "nb") {
#   pred <- get_pred_nb(train.data, test.data)
# } else if (model == "svm") {
#   pred <- get_pred_svm(train.data, test.data)
# } else if (model == "logreg") {
#   pred <- get_pred_logit(train.data, test.data)
# } else if (model == "default") {
#   pred <- get_pred_default(train.data, test.data)
# }
model <- train(classe~., data=dataTrain.train, method="rf", ntree=100)  # Run Random Forest Classifier
pred <- predict(model, test.data)
accuracy <- sum(dataTrain.test.predict == dataTrain.test$classe)/length(dataTrain.test.predict)
# true <- test.data[, c(which(colnames(df) == output))]  # extract true values from test set
# accuracy <- true / length(pred)  # computer Accuracy
score[ii] <- accuracy  # save the score
}
install.packages("randomForest")
for (ii in 1:length(folds)) {
test.index <- folds[[ii]]  # extract test index
train.data <- df[-test.index, ]  # assemble training data
test.data <- df[test.index, ]  # assemble test data
# if (grepl("nn", model)) {
#   k.nn <- as.integer(sub("^\\D*(\\d+).*$", "\\1", model))  # parse the K nearest neighbor from model name
#   pred <- get_pred_knn(train.data, test.data, k.nn)  # run with addional parameter for knn model predictor
# } else if (model == "nb") {
#   pred <- get_pred_nb(train.data, test.data)
# } else if (model == "svm") {
#   pred <- get_pred_svm(train.data, test.data)
# } else if (model == "logreg") {
#   pred <- get_pred_logit(train.data, test.data)
# } else if (model == "default") {
#   pred <- get_pred_default(train.data, test.data)
# }
model <- train(class ~ ., data= train.data, method="rf", ntree=100)  # Run Random Forest Classifier
# model <- randomForest(formula = class ~ ., data = train.data, ntree = 100,mtry = 2, importance = TRUE)
pred <- predict(model, test.data)
accuracy <- sum(dataTrain.test.predict == dataTrain.test$classe)/length(dataTrain.test.predict)
# true <- test.data[, c(which(colnames(df) == output))]  # extract true values from test set
# accuracy <- true / length(pred)  # computer Accuracy
score[ii] <- accuracy  # save the score
}
for (ii in 1:length(folds)) {
test.index <- folds[[ii]]  # extract test index
train.data <- df[-test.index, ]  # assemble training data
test.data <- df[test.index, ]  # assemble test data
# if (grepl("nn", model)) {
#   k.nn <- as.integer(sub("^\\D*(\\d+).*$", "\\1", model))  # parse the K nearest neighbor from model name
#   pred <- get_pred_knn(train.data, test.data, k.nn)  # run with addional parameter for knn model predictor
# } else if (model == "nb") {
#   pred <- get_pred_nb(train.data, test.data)
# } else if (model == "svm") {
#   pred <- get_pred_svm(train.data, test.data)
# } else if (model == "logreg") {
#   pred <- get_pred_logit(train.data, test.data)
# } else if (model == "default") {
#   pred <- get_pred_default(train.data, test.data)
# }
# model <- train(class ~ ., data= train.data, method="rf", ntree=100)  # Run Random Forest Classifier
model <- randomForest(formula = class ~ ., data = train.data, ntree = 100,mtry = 2, importance = TRUE)
pred <- predict(model, test.data)
accuracy <- sum(dataTrain.test.predict == dataTrain.test$classe)/length(dataTrain.test.predict)
# true <- test.data[, c(which(colnames(df) == output))]  # extract true values from test set
# accuracy <- true / length(pred)  # computer Accuracy
score[ii] <- accuracy  # save the score
}
library(randomForest)
for (ii in 1:length(folds)) {
test.index <- folds[[ii]]  # extract test index
train.data <- df[-test.index, ]  # assemble training data
test.data <- df[test.index, ]  # assemble test data
# if (grepl("nn", model)) {
#   k.nn <- as.integer(sub("^\\D*(\\d+).*$", "\\1", model))  # parse the K nearest neighbor from model name
#   pred <- get_pred_knn(train.data, test.data, k.nn)  # run with addional parameter for knn model predictor
# } else if (model == "nb") {
#   pred <- get_pred_nb(train.data, test.data)
# } else if (model == "svm") {
#   pred <- get_pred_svm(train.data, test.data)
# } else if (model == "logreg") {
#   pred <- get_pred_logit(train.data, test.data)
# } else if (model == "default") {
#   pred <- get_pred_default(train.data, test.data)
# }
# model <- train(class ~ ., data= train.data, method="rf", ntree=100)  # Run Random Forest Classifier
model <- randomForest(formula = class ~ ., data = train.data, ntree = 100,mtry = 2, importance = TRUE)
pred <- predict(model, test.data)
accuracy <- sum(dataTrain.test.predict == dataTrain.test$classe)/length(dataTrain.test.predict)
# true <- test.data[, c(which(colnames(df) == output))]  # extract true values from test set
# accuracy <- true / length(pred)  # computer Accuracy
score[ii] <- accuracy  # save the score
}
for (ii in 1:length(folds)) {
test.index <- folds[[ii]]  # extract test index
train.data <- df[-test.index, ]  # assemble training data
test.data <- df[test.index, ]  # assemble test data
# if (grepl("nn", model)) {
#   k.nn <- as.integer(sub("^\\D*(\\d+).*$", "\\1", model))  # parse the K nearest neighbor from model name
#   pred <- get_pred_knn(train.data, test.data, k.nn)  # run with addional parameter for knn model predictor
# } else if (model == "nb") {
#   pred <- get_pred_nb(train.data, test.data)
# } else if (model == "svm") {
#   pred <- get_pred_svm(train.data, test.data)
# } else if (model == "logreg") {
#   pred <- get_pred_logit(train.data, test.data)
# } else if (model == "default") {
#   pred <- get_pred_default(train.data, test.data)
# }
# model <- train(class ~ ., data= train.data, method="rf", ntree=100)  # Run Random Forest Classifier
model <- randomForest(formula = class ~ ., data = train.data, ntree = 100,mtry = 2, importance = TRUE)
pred <- predict(model, test.data)
accuracy <- sum(pred == test.data$class)/length(pred)
# true <- test.data[, c(which(colnames(df) == output))]  # extract true values from test set
# accuracy <- true / length(pred)  # computer Accuracy
score[ii] <- accuracy  # save the score
}
---
title: "Human Activity Recognition"
author: "Yuxiang Hu"
output:
html_document:
fig_height: 5
fig_width: 5
toc: yes
toc_depth: 5
theme: sandstone
pdf_document:
toc: yes
---
# Introduction
Human activity recognition is a growing field with numerous applications. Companies like BodyMedia and Fitbit sell personal activity monitors worn on the left arm and waist, respectively. One can imagine numerous applications for this technology. For the purposes of this project, suppose your company would like to construct a similar device. Toward that end, you have been provided a dataset containing approximately 8 hours of accelerometer data for each of 4 individuals. Records represent 3-axis acceleration measurements taken from 4 accelerometers worn on the waist, left thigh, right arm, and right ankle. Each measurement is taken over a time window of 150ms and presented in temporal order, without a time stamp. The activity of each participant is categorized into 5 classes; sitting, sitting-down, standing, standing-up, and walking.
# Data Preparation and Summary
## Step 1 - Load Data and load libraries
```{r}
library(gplots)
library(ggplot2)
library(FNN)
library(plyr)
library(zoo)
library(e1071)
library(randomForest)
# Utility function for importing data from a csv (comma-separated values, flat table) file
import.csv <- function(filename) {
return(read.csv(filename, dec = ",", sep = ";", header = TRUE))
}
# Utility function for exporting data to csv file
# Note that csv files are very portable, practically all tools understand them,
# including Microsoft Excel
write.csv <- function(ob, filename) {
write.table(ob, filename, quote = FALSE, sep = ";", dec = ",", row.names = FALSE)
}
my.data <- import.csv("dataset-har-PUC-Rio-ugulino.csv")
```
## Step 2 - Clean data
```{r}
# Function to remove special characters
my.data <- transform(my.data,
z4 = as.integer(as.character(z4))
)
summary(my.data)
my.data <- my.data[!is.na(my.data$z4),]  # Drop Z4 na record
```
## Step 3 - Data Summary
```{r}
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
# Function to determine missing symbol
is.missing.symbol <- function(x) {
if (nchar(trim(x)) == 0) {
missing = 1
} else {
missing = 0
}
return(missing)
}
brief <- function(df) {
# those two list store two indexs, one for real and another for symbolic attributes
real.index <- NULL
symbol.index <- NULL
num_row <- nrow(df)  # count number of rows
num_att <- ncol(df)  # count number of columns
for (ii in 1:num_att) {
this.att <- df[, ii]
if (is.numeric(this.att)) {
real.index <- c(real.index, ii)
}
if (is.factor(this.att)) {
symbol.index <- c(symbol.index, ii)
}
}
cat("This data set has", num_row, "rows,", num_att, "attributes")  # write a line here: use cat function to print the "This data set has xxx row, xxx attributes
real.out <- NULL  # this data frame store information for real valued attributes
for (index in real.index) {
this.att <- df[, index]  # extract a specific column
att_name <- colnames(df)[index]  # get attribute name using colnames function
num_missing <- sum(is.na(this.att))  # count number of missing values using is.na function
Min <- round(min(this.att), 2)  # min
Max <- round(max(this.att), 2)  # max
Mean <- round(mean(this.att), 2)  # mean
Median <- round(median(this.att), 2)  # median
Sdev <- round(sd(this.att), 2)  # standard deviation
Var <- round(var(this.att), 2)  # variance
this.line <- data.frame(Attribute_ID = index, Attribute_Name = att_name, Missing = num_missing,
Min, Max, Mean, Median, Sdev, Variance = Var) # assemble into a line
real.out <- rbind(real.out, this.line) # concatenate to get a data frame
}
cat("real valued attributes\n")
cat("======================\n")
print(real.out)
# gather stats for symbolic attributes
symbol.out <- NULL #this data frame store information for real valued attributes
max_MCV = 5
for (index in symbol.index) {
this.att <- df[, index]
att_name <- colnames(df)[index]  # get attribute name
#count number of missing values in symbolic attribute
num_missing <- length(this.att[this.att == ''])
non_missing_id <- which(unlist(lapply(this.att, is.missing.symbol)) == 0)
this.att <- this.att[non_missing_id]
#count MCV
arity <- nlevels(this.att[this.att!='',drop=TRUE])
num_MCV <- min(max_MCV, arity)
count.tbl <- as.data.frame(table(this.att))
sorted <- count.tbl[order(-count.tbl$Freq), ][1:num_MCV, ]
MCV_str <- ""
for (kk in 1:nrow(sorted)) {
MCV_value <- sorted[kk, c("this.att")]  # MCV string
MCV_count <- sorted[kk, c("Freq")]  # MCV count
this_str <- paste(MCV_value, "(", MCV_count, ")", sep = "")
MCV_str <- paste(MCV_str, this_str, sep = " ")
}
this.line <- data.frame(Attribute_ID = index, Attribute_Name = att_name, Missing = num_missing,
arity, MCVs_counts = MCV_str)
symbol.out <- rbind(symbol.out, this.line)
}
cat("symbolic attributes\n")
cat("===================\n")
print(symbol.out)
}
brief(my.data)
```
# Cross Validation
In order to avoid data leakage, we will not using K fold validation process, because we would avoid same user's data present in both training and testing data.
Therefore, instead, we will choose to alternate data for each user to be testing data set.
```{r}
do_cv_class <- function(df, output, split.by, model) {
nn <- nrow(df)  # number of data points
nf <- ncol(df)  # number of features
df <- df[,c(which(colnames(df) != output), which(colnames(df) == output))]  # Move output to the last column
folds <- split(1:nn, df[,c(which(colnames(df) == split.by))])  # user split.by column to split folds.
score <- rep(NA, length(folds))  # create a list to hold the mse for each folds
for (ii in 1:length(folds)) {
test.index <- folds[[ii]]  # extract test index
train.data <- df[-test.index, ]  # assemble training data
test.data <- df[test.index, ]  # assemble test data
# if (grepl("nn", model)) {
#   k.nn <- as.integer(sub("^\\D*(\\d+).*$", "\\1", model))  # parse the K nearest neighbor from model name
#   pred <- get_pred_knn(train.data, test.data, k.nn)  # run with addional parameter for knn model predictor
# } else if (model == "nb") {
#   pred <- get_pred_nb(train.data, test.data)
# } else if (model == "svm") {
#   pred <- get_pred_svm(train.data, test.data)
# } else if (model == "logreg") {
#   pred <- get_pred_logit(train.data, test.data)
# } else if (model == "default") {
#   pred <- get_pred_default(train.data, test.data)
# }
# model <- train(class ~ ., data= train.data, method="rf", ntree=100)  # Run Random Forest Classifier
model <- randomForest(formula = class ~ ., data = train.data, ntree = 100, mtry = 2, importance = TRUE)
pred <- predict(model, test.data)
accuracy <- sum(pred == test.data$class)/length(pred)
# true <- test.data[, c(which(colnames(df) == output))]  # extract true values from test set
# accuracy <- true / length(pred)  # computer Accuracy
score[ii] <- accuracy  # save the score
}
return(score)
}
```
